# 프로세스



🤔 프로세스와 스레드의 차이는 무엇인가요?    
🤔 교착상태란 무엇이며, 교착상태가 발생하기 위해서는 어떤 조건이 있어야 하나요?    
🤔 교착상태의 해결법은 무엇인가요?        
🤔 뮤텍스와 세마포어에 대해서 설명해 보시오.   
🤔 컨텍스트 스위칭이란 무엇인가요?     
🤔 경쟁 상태란 무엇인가요?    
🤔 프로세스 혹은 스레드의 동기화란 무엇인가요?    
🤔 사용자 수준의 스레드와 커널 수준의 스레드의 차이는 무엇인가요?    
🤔 CPU 스케줄링이란 무엇인가요?     
🤔 CPU 스케줄링 방법에는 대표적으로 어떤 것들이 있나요?   
🤔 동기와 비동기, 블로킹과 넌블로킹의 차이는 무엇인가요?   

</br>

---

# 프로세스(Process)
> Process is program in execution   
        
프로세스란 **실행중인 프로그램**을 의미한다.     
      
보다 자세히 설명하자면,   
`디스크에 존재`하는 프로그램이 `메모리에 올라가` `실행 중`인 상태이며      
`CPU를 보유`하고 있어 `기계어 명령 실행이 가능`한 단계이다.     
                 
프로세스는 일반적으로 다음과 같은 요소를 포함한다.   

* **스택 :** 함수의 매개 변수, 복귀 주소와 로컬 변수와 같은 임시적인 자료를 보유   
* **데이터 섹션 :** 전역 변수를 수록    
* **힙 :** 동적으로 할당되는 메모리   
* **테스트 섹션 :** 프로그램 코드      
* **프로그램 카운터 :** 다음에 실행할 명령어의 주소를 보유하고 있어, 실행할 기계어 코드의 위치를 지정        

  
**프로세스의 종류**     
    
* 사용자 프로세스 : 응용 프로그램이 실행되면서 생성된 프로세스            
* 시스템 프로세스 : 운영체제가 필요에 의해 생성하는 프로세스       
  
# 프로세스의 문맥 (Process Context)
               
**프로세스 `문맥` :**                               
특정 프로세스의를 대상으로 [시스템 콜](https://ko.wikipedia.org/wiki/%EC%8B%9C%EC%8A%A4%ED%85%9C_%ED%98%B8%EC%B6%9C) 등을 통해      
`주소 공간`, `레지스터 존재하는값`, `커널에서 수행한 일의 상태` 와 같은     
**그 프로세스에 관해 커널이 관리하는 각종 정보**를 말한다.               
            
즉, 프로세스가 **현재 어떤 상태에서 무엇을 수행하고 있는지를 알기 위한 정보를 의미한다.**     
            
시분할 환경에서 프로세스는 수행 중 계속해서 중단과 속개를 반복한다.          
즉, 프로세스는 상태에 변화가 있는 동적인 개체이므로 이에 대한 정보를 유지하고 있어야한다.      
이 때 프로세스 중단시에 **보존되고 속개 시 다시 복구되어야하는 프로세스의 모든 실행정보**를 `문맥`이라고 한다.  
                
이러한 프로세스 문맥은 크게 세가지로 분류한다.

1. 하드웨어 문맥
2. 프로세스의 주소 공간
3. 커널 상의 문맥
  
이 3가지에 대해서 자세히 다루는건 오버하는 것 같아서     
PCB에 대해서만 정리하고 일단 넘어가겠습니다.      
   
## 프로세스 제어 블록(Process Control Block, PCB)
> 프로세스의 상태를 저장하고 있는 고유의 블록  
              
`PCB`는 특정 **프로세스에 대한 중요한 정보를 저장** 하고 있는 운영체제 커널내의 자료구조이다.   
운영체제는 프로세스를 관리하기 위해 **프로세스의 생성과 동시에 고유한 PCB 를 생성** 한다.   
프로세스는 CPU 를 할당받아 작업을 처리하다가도 프로세스 전환이 발생하면    
진행하던 작업을 저장하고 CPU 를 반환해야 하는데,        
이때 **작업의 진행 상황을 모두 `PCB` 에 저장** 하게 된다.         
그리고 다시 CPU 를 할당받게 되면 PCB 에 저장되어있던 내용을 불러와    
**이전에 종료됐던 시점부터 다시 작업을 수행한다.**         
           
> **정리 :** 프로세스마다 상태를 저장하는 PCB를 생성, 이후 해당 프로세스 실행시 PCB 기준으로 다시 동작      
      
_PCB 에 저장되는 정보_
     
![87313931-8b6c9180-c55d-11ea-9b37-1304dce4631e](https://user-images.githubusercontent.com/50267433/110240291-9497ec00-7f8e-11eb-9ad2-b6fde99b4789.jpg)         
   
* **Pointer :** 각종 자원 요소에 대한 포인터  
  * 부모/자식 프로세스에 대한 포인터
  * 프로세스가 위치한 메모리 블록의 포인터 
  * 할당된 자원에 대한 포인터         
* **Process Number(ID), PID :** 프로세스가 생성될 때 할당 받는 프로세스 식별번호  
* **Process Counter :** new, ready, running, waiting, terminated 등의 상태를 저장
* **Program Counter :** 프로세스가 다음에 실행할 명령어의 주소       
* **Registers :** 중앙처리장치의 각종 레지스터 상태를 저장하기 위한 공간,    
  레지스터의 저장값이 앞으로 수행할 프로세스에 관한 정보로 바뀐다.             
* **Memory limits :** 메모리 관리 시스템에 대한 정보가 포함된다. `페이지 테이블`, `세그먼트 테이블` 등이 포함될 수 있다.  
* **List of open files :** 할당받은 자원들에 대한 정보를 가지고 있다.  

    
# 프로세스 상태(Life cycle)        
프로세스 상태는 크게 `생성`, `실행`, `준비`, `봉쇄`, `종료` 상태로 나눌 수 있다.       
   
> 📌 아래에 나와있는 3개의 그림은 모두 같다. 단지 모양/언어만 다를뿐이다.   

![프로세스 생명주기](https://user-images.githubusercontent.com/50267433/110227074-d77aa500-7f37-11eb-967a-0bd17ecd02ad.png)     
![프로세스 생명주기2](https://user-images.githubusercontent.com/50267433/110227142-91721100-7f38-11eb-9e0b-8507cccb657b.png)   
           
* **New :** 
  * 프레세스가 생성되어 `PCB`가 생성되고 `OS 커널`에 등록된 상태를 의미한다.          
  * 단, 메모리 검사가 이루어지지 않아 아직 `OS`에 의해 승인을 받지 못한 상태이다. 
  * 만약 메모리 공간이 부족하면 `프로세스`는 보류준비 상태가 된다.          
      * **보류 준비 상태 :**   
      * 메모리 공간이 부족할 때 OS는 당분간 메모리를 회수해도 문제가 되지 않을 프로세스들을 선택해 보류시킨다.   
      * 이렇게 보류시킨 프로세스를 다시 메모리로 올리는 작업을 Swapping이라고 한다.  
      * 메모리 공간을 뺏기고 디스크로 나가는 것 -> Swapped Out
      * 나중에 다시 메모리로 들어오는 것 -> Swapped In  
   
* **Ready :**    
  * `OS 커널`에 등록된 프로세스가 `Ready Queue`에 올라온 상태`(Admit)`를 의미하며, 아직 `CPU`를 할당받지 못한 상태이다.                
  * 반대로, 프로그램 실행을 위한 모든 메모리가 준비되었기에 `CPU`만 할당받으면 언제든지 실행 가능한 상태이기도 하다.            

* **Running :**     
  * `Ready Queue`에 등록된 프로세스가 특정 알고리즘에 의해 `CPU`를 할당받아`(Dispatch)` 실행중인 상태이다.           
  * **✨ context switch :**    
    * 만약, 실행중인 프로세스가 제한된 시간내에 완료되지 않는다면 다시 Ready 상태로 `Timeout` 이 된다.          
    * 또한, 입출력이나 바로 처리할 수 없는 이벤트를 발생시킨다면,   
      즉 CPU를 다른 프로세스에 넘겨주고 잠시 프로세스를 중단해야 할 경우(어차피 정보는 PCB에 남음) `Waiting`상태로 `Wait` 된다.     
      이렇듯, CPU를 다른 프로세서에게 넘기면서 현재 문맥을 저장하고 새로운 프로세스의 문맥을 세팅하는 것을 문맥 교환(context switch)이라고 한다.        
      
* **Waiting(Blocked) :**    
  * CPU를 다른 프로세스에게 양보하고 해당 프로세스가 종료되기를 기다리는 상태  
  * **waiting -> ready 가는 조건 다시 확인하고 작성하자**   
  
* **terminated :**   
  * 프로세스의 실행이 완전히 종료되었다는 상태를 나타낸다.   
  * 프로세스의 실행이 종료되었으니 할당된 CPU와 자원을 모두 반납하고 종료된다.   
  * 단, PCB는 OS(커널)에 존재하므로 해당 PCB 또한 제거하면 프로세스는 완벽히 종료되었다 말할 수 있다.    
     
**문맥 교환**       
문맥교환이란, 다른 사용자 프로세스로 CPU의 제어권이 이양되는 과정을 말합니다.     
다만,`타이머 인터럽트`와 `입출력을 위한 시스템콜`을 제외한 인터럽트 발생시,     
`모드 비트(mode bit)` 변경을 통한 **명령 권한의 차이가 대부분이기 때문에**       
이런 경우는 **문맥교환이 발생했다고 하지 않는다.** -> 이거 설명해주실 수 있나요..?      

# 프로세스 스케줄링     
프로세스 스케줄링이란, **CPU를 사용하려고 하는 프로세스들 사이의 우선 순위를 관리하는 일을 말한다.**           
스케줄링은 `처리율`과 `CPU 이용률`을 증가시키고 `오버헤드`/`응답시간`/`반환시간`/`대기시간`을 최소화 시키기 위한 기법이다.    
죽, CPU가 쉬지않고 계속 열심히 일할 수 있도록 효율적인 계획을 잡아주는 것이다.   
     
![process scheduling](https://user-images.githubusercontent.com/50267433/110241762-d8daba80-7f95-11eb-8ff0-852ea8b8cbc6.png)    
   
_프로세스를 스케줄링하기 위한 Queue 에는 세 가지 종류가 존재한다._
* Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합
* Ready Queue : 현재 메모리 내에 있으면서 CPU 를 잡아서 실행되기를 기다리는 프로세스의 집합
* Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합

각각의 Queue 에 프로세스들을 넣고 빼주는 스케줄러에도 크게 **세 가지 종류가** 존재한다.
   
* 장기 스케줄링 : 어떤 프로세스를 커널에 등록할 것인가를 정한다.  
* 중기 스케줄링 : 어떤 프로세스에게 메모리를 할당 할 것인가를 정한다.  
* 단기 스케줄링 : 어떤 프로세스에게 CPU를 할당할 것인가를 정한다.  

## 장기 스케줄러(long time Scheduler)    
> 장기 스케줄러(long time Scheduler) = 작업 스케줄러(job Scheduler)   
         
메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 
대용량 메모리(일반적으로 디스크)에 임시로 저장된다.   
이 `pool`에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 `ready queue`로 보낼지 결정하는 역할을 한다.
       
* 메모리와 디스크 사이의 스케줄링을 담당.  
* 프로세스에 `memory(및 각종 리소스)`를 할당`(admit)`  
* `degree of Multiprogramming` 제어  
  (실행중인 프로세스의 수 제어)
* 프로세스의 상태     
  `new -> ready(in memory)`  

_cf) 메모리에 프로그램이 너무 많이 올라가도, 너무 적게 올라가도 성능이 좋지 않은 것이다.   
참고로 `time sharing system` 에서는 장기 스케줄러가 없다. 그냥 곧바로 메모리에 올라가 `ready` 상태가 된다._
    
 
## 중기 스케줄러(medium term schduler)
         
중기 스케줄러는 너무 많은 프로세스에게       
메모리를 할당해 시스템의 성능이 저하대는 경우를 방지하기 위해        
 **메모리에 적재되어 있는 `프로세스의 수를 관리`하는 역할을 합니다.**  
최근에는 장기 스케줄러 대신에 중기 스케줄러를 두는 경우가 많아졌다.    
   
**메모리에 적재된 프로세스의 수를 왜 관리해야 할까? 🤔**   
             
메모리에 적재되어 있는 프로세스의 수가 많아지면           
그 만큼 각각의 프로세스에 할당되는 메모리양은 당연히 줄어 들게 된다.         
왜냐하면, 스레드는 자원을 공유하지만 **프로세스는 자원을 공유하지 않기 때문이다.**     
         
이런 경우 `스왑 아웃(swap out)`이 수시로 발생하게 되고        
이에 따른 오버헤드 발생으로 인해 시스템 성능이 저하될 수 있기 때문이다.     
   
*스왑 아웃(swap out) : 메모리의 내용을 디스크로 이동시키는 행위
*스왑 인(swap in) : 디스크의 내용을 메모리로 이동시키는 행위
      
중기 스케줄러에 의해 스왑 당한 프로세서의 상태는 `중지(suspended, stopped) 상태`가 된다.   

* 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절하는 스케줄러.      
* 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄 **(swapping)**     
* 프로세스에게서 memory 를 deallocate       
* degree of Multiprogramming 제어        
* 프로세스의 상태 `ready` -> `suspended`       


_Process state - suspended_   
Suspended(stopped) :   
외부적인 이유로 프로세스의 수행이 정지된 상태로 메모리에서 내려간 상태를 의미한다.   
프로세스 전부 디스크로 `swap out`된다.      
blocked 상태는 다른 I/O 작업을 기다리는 상태이기 때문에 `스스로 ready state 로 돌아갈 수 있지만`      
이 상태는 **외부적인 이유로 suspending 되었기 때문에 스스로 돌아갈 수 없다.**        
      
## 단기 스케줄러(short term scheduler)
> 단기 스케줄러(short term scheduler) = CPU 스케줄러 

`Ready 상태`의 프로세스 중에서 어떤 프로세스를 다음 번 `Running 상태`로 만들것인지 결정하는 역할을 한다.      
다시 말해, `Ready Queue`에 있는 여러 프로세스들 중에서 어떤 프로세스에게 `CPU를 할당할 것인가`를 결정한다.     
        
* CPU 와 메모리 사이의 스케줄링을 담당.
* Ready Queue 에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정.
* 프로세스에 CPU 를 할당(scheduler dispatch)
* 프로세스의 상태 : `ready` -> `running` -> `waiting` -> `ready`
    
</br>
   
## CPU 스케줄러(단기 스케줄러)    
   
_스케줄링 대상은 Ready Queue 에 있는 프로세스들이다._
   
### FCFS(First Come First Served)
   
**특징**     
* **먼저 온 고객을 먼저 서비스해주는 방식, 즉 먼저 온 순서대로 처리.**   
* **비선점형(Non-Preemptive) 스케줄링**     
  일단 CPU 를 잡으면 `CPU burst` 가 완료될 때까지 CPU 를 반환하지 않는다.       
  할당되었던 CPU 가 반환될 때만 스케줄링이 이루어진다.
   
**문제점**    
* `convoy effect`  
  소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상이 발생한다.

</br>

### SJF(Shortest - Job - First)
  
**특징**   
* 다른 프로세스가 먼저 도착했어도 `CPU burst time`이 짧은 프로세스에게 선 할당
* **비선점형(Non-Preemptive) 스케줄링**  
     
**문제점**   
* `starvation - 기아상태`        
  효율성을 추구하는게 가장 중요하지만 특정 프로세스가 지나치게 차별받으면 안되는 것이다.       
  이 스케줄링은 **극단적으로 CPU 사용이 짧은 job 을 선호한다.**        
  그래서 **사용 시간이 긴 프로세스는 거의 영원히 CPU 를 할당받을 수 없다.**   
  
</br>

### SRT(Shortest Remaining time First)
  
**특징**     
* 새로운 프로세스가 도착할 때마다 새로운 스케줄링이 이루어진다.
* **선점형 (Preemptive) 스케줄링**    
  현재 수행중인 프로세스의 `남은 burst time` 보다     
  더 짧은 `CPU burst time` 을 가지는 새로운 프로세스가 도착하면 **CPU 를 뺏는다.**   
          
**문제점**
* `starvation - 기아상태`    
  새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문에 `CPU burst time(CPU 사용시간)`을 측정할 수가 없다.
     
</br>

### Priority Scheduling
   
**특징**    
* 우선순위가 가장 높은 프로세스에게 CPU 를 할당한다.    
  * 우선순위란 정수로 표현하게 되고 작은 숫자가 우선순위가 높다.
* **선점형 스케줄링(Preemptive) 방식**  
  더 높은 우선순위의 프로세스가 도착하면 실행중인 프로세스를 멈추고 CPU 를 선점한다.
* **비선점형 스케줄링(Non-Preemptive) 방식**  
  더 높은 우선순위의 프로세스가 도착하면 `Ready Queue 의 Head` 에 넣는다.  
    
**문제점**    
* starvation
* 무기한 봉쇄(Indefinite blocking)  
  실행 준비는 되어있으나 CPU 를 사용못하는 프로세스를 CPU 가 무기한 대기하는 상태
     
**해결책**    
* `aging` : 아무리 우선순위가 낮은 프로세스라도 오래 기다리면 우선순위를 높여주자.
   
</br>

### Round Robin
     
**특징**      
* 현대적인 CPU 스케줄링 (디폴트로 알고 있음)      
* 각 프로세스는 `동일한 크기의 할당 시간(time quantum)`을 갖게 된다.   
* 할당 시간이 지나면 프로세스는 선점당하고 `ready queue` 의 제일 뒤에 가서 다시 줄을 선다.
* `RR`은 **CPU 사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적이다.**  
* `RR`이 가능한 이유는 프로세스의 context 를 save 할 수 있기 때문이다. -> Context Switch   
        
**장점**     
* `Response time`이 빨라진다.    
  n 개의 프로세스가 `ready queue`에 있고 할당시간이 q(time quantum)인 경우 각 프로세스는 q 단위로 CPU 시간의 1/n 을 얻는다.   
  즉, 어떤 프로세스도 (n-1)q time unit 이상 기다리지 않는다.
* 프로세스가 기다리는 시간이 CPU 를 사용할 만큼 증가한다.  
  공정한 스케줄링이라고 할 수 있다.  

**주의할 점**     
설정한 `time quantum`이 너무 커지면 `FCFS`와 같아진다.     
또 너무 작아지면 스케줄링 알고리즘의 목적에는 이상적이지만 잦은 `context switch` 로 `overhead`가 발생한다.   
그렇기 때문에 적당한 `time quantum`을 설정하는 것이 중요하다.    
         
 
# 동기와 비동기의 차이
## 비유를 통한 쉬운 설명
 
해야할 일(task)가 빨래, 설거지, 청소 세 가지가 있다고 가정한다.        
  
이 일들을 동기적으로 처리한다면 빨래를 하고 설거지를 하고 청소를 한다.    
    
비동기적으로 일을 처리한다면     
   
* 빨래하는 업체에게 빨래를 시킨다.     
* 설거지 대행 업체에 설거지를 시킨다.       
* 청소 대행 업체에 청소를 시킨다.    
     
셋 중 어떤 것이 먼저 완료될지는 알 수 없다.     
일을 모두 마친 업체는 나에게 알려주기로 했으니 나는 다른 작업을 할 수 있다.     
이 때는 백그라운드 스레드에서 해당 작업을 처리하는 경우의 비동기를 의미한다.   

## Sync vs Async
    
일반적으로 동기와 비동기의 차이는     
**메소드를 실행시킴과 `동시에` 반환 값이 기대되는 경우를 `동기`** 라고 표현하고      
그렇지 않은 경우에 대해서 **비동기** 라고 표현한다.        
       
`동시에`라는 말은 실행되었을 때 **값이 반환되기 전까지는 `blocking`되어 있다는 것을 의미한다.**         
비동기의 경우,    
`blocking`되지 않고 [이벤트 큐](https://www.zerocho.com/category/JavaScript/post/597f34bbb428530018e8e6e2)에 넣거나 백그라운드 스레드에게 해당 `task`를 위임하고   
바로 다음 코드를 실행하기 때문에 기대되는 값이 바로 반환되지 않는다.          
         
이 부분에 대해서는 조금 더 할 말이 많습니다.      
동기,비동기는 알겠지만 Blocking None-Blocking이란 무엇이지? 라는 생각도 듭니다.   
이 부분에 대해서 학습은 했지만, 아직 정리를 하지 않았기에 [링크](https://www.youtube.com/watch?v=IdpkfygWIMk&ab_channel=%EC%9A%B0%EC%95%84%ED%95%9CTech)만 남기겠습니다.     


# 프로세스 동기화

## Critical Section(임계영역)

멀티 스레딩시에 동일한 자원을 동시에 접근하는 작업을 실행하는 코드 영역을 `Critical Section` 이라 칭한다.
(e.g. 공유하는 변수 사용, 동일 파일을 사용하는 등)    
     
## Critical Section Problem(임계영역 문제)
           
**✔ RaceCondition :** 공유 자원에 대해 여러 개의 프로세스가 동시에 접근하기 위해 경쟁하는 상태를 말한다.(스레드)             
         
프로세스들이 `Critical Section`을 함께 사용할 수 있는 프로토콜을 설계하는 것이다.    


**Requirements(해결을 위한 기본조건)**
* **Mutual Exclusion(상호 배제):**  
  프로세스 P1 이 `Critical Section`에서 실행중이라면,    
  다른 프로세스들은 그들이 가진 `Critical Section`에서 실행될 수 없다.
* **Progress(진행):**     
  `Critical Section`에서 실행중인 프로세스가 없고,      
  별도의 동작이 없는 프로세스들만 `Critical Section`진입 후보로서 참여될 수 있다.    
* **Bounded Waiting(한정된 대기):**    
  `P1` 가 `Critical Section`에 진입 신청 후 부터 받아들여질 때가지,       
  다른 프로세스들이 `Critical Section`에 진입하는 횟수는 제한이 있어야 한다.   
   
## 해결책    
  
**Lock**  
* 하드웨어 기반 해결책으로써,     
동시에 공유 자원에 접근하는 것을 막기 위해 `Critical Section` 에 진입하는 프로세스는 Lock 을 획득하고    
Critical Section 을 빠져나올 때, Lock 을 방출함으로써 동시에 접근이 되지 않도록 한다.    
      
자바에서는 `synchronized 키워드`나 `java.util.concurrent.ReetrantLock` 이라고 존재      
     
**한계**   
* 다중처리기 환경에서는 시간적인 효율성 측면에서 적용할 수 없다.
      
## Semaphores(세마포)

* 소프트웨어상에서 `Critical Section` 문제를 해결하기 위한 동기화 도구
     
**종류**   

OS 는 `Counting/Binary 세마포`를 구분한다

* **이진 세마포 MUTEX**       
  MUTEX 라고도 부르며,        
  상호배제의 (Mutual Exclusion)의 머릿글자를 따서 만들어졌다.       
  이름 그대로 0 과 1 사이의 값만 가능하며, 다중 프로세스들 사이의 `Critical Section` 문제를 해결하기 위해 사용한다.    
   
* 카운팅 세마포     
  **가용한 개수를 가진 자원** 에 대한 접근 제어용으로 사용되며,      
  세마포는 그 가용한 **자원의 개수** 로 초기화 된다.      
  자원을 사용하면 세마포가 감소, 방출하면 세마포가 증가 한다.       
           
[세마포/뮤텍스 동작과정 및 차이점](https://www.youtube.com/watch?v=DvF3AsTglUU&feature=emb_title&ab_channel=HowTo)  
       
**뮤텍스와 세마포어의 특징**
* 뮤텍스 : 한 쓰레드, 프로세스에 의해 소유될 수 있는 Key🔑를 기반으로 한 상호배제기법     
오직 1개의 프로세스 또는 스레드만 접근 가능하다.
임계영역에 들어갈 때 lock을 걸어 다른 프로세스 또는 스레드가 접근하지 못하도록 하고, 임계영역에서 나올 때 unlock으로 다른 프로세스 또는 쓰레드가 접근할 수 있도록 한다.

* 세마포어 : 현재 공유자원에 접근할 수 있는 스레드 또는 프로세스의 수를 나타내는 값을 두어 상호배제를 달성하는 기법       
세마포어 변수만큼 프로세스 또는 스레드가 접근할 수 있다.      
현재 수행중인 프로세스가 아닌 다른 프로세스가 세마포어를 해제할 수 있다.  
  
       
**단점**       
* `Busy Waiting(바쁜 대기)/Spin lock`      
Semaphore 초기 버전에서 `Critical Section` 에 진입해야하는 프로세스는 진입 코드를 계속 반복 실행해야 하며, CPU 시간을 낭비했었다.    
이를 `Busy Waiting`이라고 부르며 특수한 상황이 아니면 비효율적이다.            
일반적으로는 `Semaphore`에서 `Critical Section`에 진입을 시도했지만 실패한 프로세스에 대해 `Block`시킨 뒤,       
`Critical Section`에 자리가 날 때 다시 깨우는 방식을 사용한다.       
이 경우 `Busy waiting`으로 인한 시간낭비 문제가 해결된다.   
   
## Deadlock(교착상태)
      
* 세마포가 `Ready Queue`를 가지고 있고,      
* 둘 이상의 프로세스가 `Critical Section` 진입을 무한정 기다리고 있고,     
* `Critical Section`에서 실행되는 프로세스는 진입 대기 중인 프로세스가 실행되야만 빠져나올 수 있는 상황을 지칭한다.   
         
**교착상태 조건**         
교착상태는 아래에 기술된 **4가지가 조건을 모두 모두 만족해야 발생한다.**                   
         
|조건이름|설명|
|-------|----|
|**상호배제 (Mutual Exclusion)** |한 순간에 한 프로세스만이 자원을 사용할 수 있다.<br>즉, 한 프로세스에 의해 점유된 자원을 다른 프로세스들이 접근할 수 없다.|
|**점유대기 (Hold and Wait)** |이미 자원을 보유한 프로세스가 다른 자원을 요청하며 기다리고 있다.|
|**비선점 (No preemption)** |프로세스에 의해 점유된 자원을 다른 프로세스가 강제적으로 빼앗을 수 없다.|
|**환형대기 (Circular Wait)** |프로세스간에 닫힌 연결이 존재할 경우<br>블록된 프로세스가 자원을 점유하고 있는데<br>이 자원을 다른 프로세스가 원하며 대기하고 있는 상태|  
             
**교착상태**를 발생시킨다고해서 이 조건들이 잘못된 조건은 아니다.             
예시로, `상호배제`는 수행 결과의 일관성과 데이터베이스의 무결성을 위해 반드시 필요하다.           
단지, 4가지 원칙들은 교착상태를 발생시킬 수 있다는 가능성이 있다는 것이고                 
원칙을 최대한 지키면서 교착상태가 발생하지 않는 코드를 작성해야 한다는 것을 말하고 싶다.    
   
**교착상태 예방하는 방법**        
교착상태는 교착상태를 일으키는 조건 4가지를 모두 만족하면 발생한다.     
즉, 조건 4가지중 1가지라도 지키지 않을 경우 교착상태를 피할 수 있다.    
   
![예방](https://user-images.githubusercontent.com/50267433/105574264-b5bdc800-5da6-11eb-834a-77b5037aed79.PNG)    
        
## 모니터     
      
* 고급 언어의 설계 구조물로서, 개발자의 코드를 상호배제 하게끔 만든 추상화된 데이터 형태이다.  
* 공유자원에 접근하기 위한 키 획득과 자원 사용 후 해제를 모두 처리한다. (세마포어는 직접 키 해제와 공유자원 접근 처리가 필요하다.)   
      
   
# 메모리 관리 전략    
## 메모리 관리 배경       
      
각각의 **프로세스** 는 `독립된 메모리 공간`을 갖고,        
운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다.          
단지, **운영체제** 만이 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않는다.       
         
**Swapping** :      
메모리의 관리를 위해 사용되는 기법.   
표준 Swapping 방식으로는 round-robin 과 같은 스케줄링의 다중 프로그래밍 환경에서      
CPU 할당 시간이 끝난 프로세스의 메모리를 보조 기억장치(e.g. 하드디스크)로 내보내고     
다른 프로세스의 메모리를 불러 들일 수 있다.     
    
> 이 과정을 **swap** (**스왑시킨다**) 이라 한다.      
> 주 기억장치(RAM)으로 불러오는 과정을 **swap-in**,      
> 보조 기억장치로 내보내는 과정을 **swap-out** 이라 한다.      
> swap 에는 큰 디스크 전송시간이 필요하기 때문에 현재에는 메모리 공간이 부족할때 Swapping 이 시작된다.   
    
**단편화** (**Fragmentation**) :    
프로세스들이 메모리에 적재되고 제거되는 일이 반복되다보면,    
프로세스들이 차지하는 메모리 틈 사이에 사용 하지 못할 만큼의 작은 자유공간들이 늘어나게 되는데, 이것이 **단편화** 이다.   
    
단편화는 2 가지 종류로 나뉜다.

| `Process A` | free | `Process B` | free | `Process C` | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; free &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | `Process D` |
| ----------- | ---- | ----------- | ---- | ----------- | :--------------------------------------------------------------------------------------: | ----------- |
    
* **외부 단편화:**    
  메모리 공간 중 사용하지 못하게 되는 일부분.    
  물리 메모리(RAM)에서 사이사이 남는 공간들을 모두 합치면 충분한 공간이 되는 부분들이 **분산되어 있을때 발생한다고 볼 수 있다.**
* **내부 단편화:**   
  프로세스가 사용하는 메모리 공간 에 포함된 남는 부분.    
  예를들어 **메모리 분할 자유 공간이 10,000B 있고 Process A 가 9,998B 사용하게되면 2B 라는 차이** 가 존재하고,   
  이 현상을 내부 단편화라 칭한다.
      
[이 블로그를 참고하면 좋을 것 같다.](https://sycho-lego.tistory.com/9)     
          
**압축 :**   
외부 단편화를 해소하기 위해 프로세스가 사용하는 공간들을 한쪽으로 몰아, 자유공간을 확보하는 방법론 이지만, 작업효율이 좋지 않다.    
(위의 메모리 현황이 압축을 통해 아래의 그림 처럼 바뀌는 효과를 가질 수 있다)   
  
| `Process A` | `Process B` | `Process C` | `Process D` | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; free &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; |
| ----------- | ----------- | ----------- | :---------: | ------------------------------------------------------------------------------------------------------------------ |
     
### Paging(페이징)
               
하나의 프로세스가 사용하는 **메모리 공간이 연속적이어야 한다는 제약을 없애는 메모리 관리 방법**이다.         
외부 단편화와 압축 작업을 해소 하기 위해 생긴 방법론으로,          
**물리 메모리는** `Frame` 이라는 고정 크기로 분리되어 있고,            
**논리 메모리(프로세스가 점유하는)는** `Page`라  불리는 고정 크기의 블록으로 분리된다.(페이지 교체 알고리즘에 들어가는 페이지)        
         
페이징 기법을 사용함으로써 논리 메모리는 물리 메모리에 저장될 때,        
연속되어 저장될 필요가 없고 물리 메모리의 남는 프레임에 적절히 배치됨으로 외부 단편화를 해결할 수 있는 큰 장점이 있다.     
         
하나의 프로세스가 사용하는 공간은 여러개의 페이지로 나뉘어서 관리되고(논리 메모리에서),         
개별 페이지는 **순서에 상관없이** 물리 메모리에 있는 프레임에 `mapping` 되어 저장된다고 볼 수 있다.  
 
* 단점 : 내부 단편화 문제의 비중이 늘어나게 된다.      
  예를들어 페이지 크기가 1,024B 이고 **프로세스 A** 가 3,172B 의 메모리를 요구한다면      
  3 개의 페이지 프레임(1,024 \* 3 = 3,072) 하고도 100B 가 남기때문에 총 4 개의 페이지 프레임이 필요한 것이다.      
  결론적으로 4 번째 페이지 프레임에는 924B(1,024 - 100)의 여유 공간이 남게 되는 **내부 단편화** 문제가 발생하는 것이다.   
    
### Segmentation(세그멘테이션)
   
페이징에서처럼 논리 메모리와 물리 메모리를 같은 크기의 블록이 아닌, **서로 다른 크기의 논리적 단위인 세그먼트(Segment)로 분할**   
사용자가 두 개의 주소로 지정(세그먼트 번호 + 변위)          
세그먼트 테이블에는 `각 세그먼트의 기준(세그먼트의 시작 물리 주소)`과 `한계(세그먼트의 길이)`를 저장          
    
* 단점 :    
  서로 다른 크기의 세그먼트들이 메모리에 적재되고 제거되는 일이 반복되다 보면,       
  자유 공간들이 많은 수의 작은 조각들로 나누어져 못 쓰게 될 수도 있다.**(외부 단편화)**     

## 가상 메모리
           
다중 프로그래밍을 실현하기 위해서는 많은 프로세스들을 동시에 메모리에 올려두어야 한다.        
가상메모리는 **프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법** 이며,      
**프로그램이 물리 메모리보다 커도 된다는 주요 장점이 있다.**            
      
### 가상 메모리 개발 배경
      
실행되는 **코드의 전부를 물리 메모리에 존재시켜야** 했고,           
**메모리 용량보다 큰 프로그램은 실행시킬 수 없었다.**             
또한, 여러 프로그램을 동시에 메모리에 올리기에는 용량의 한계와, 페이지 교체등의 성능 이슈가 발생하게 된다.   
또한, 가끔만 사용되는 코드가 차지하는 메모리들을 확인할 수 있다는 점에서,           
**불필요하게 전체의 프로그램 전체가 메모리에 올라와 있어야 하는게 아니라는 것을 알 수 있다.**        
            
**프로그램의 일부분만 메모리에 올릴 수 있다면...**      
* 물리 메모리 크기에 제약받지 않게 된다.  
* 더 많은 프로그램을 동시에 실행할 수 있게 된다. 이에 따라 `응답시간`은 유지되고, `CPU 이용률`과 `처리율`은 높아진다.   
* [swap](#메모리-관리-배경)에 필요한 입출력이 줄어들기 때문에 프로그램들이 빠르게 실행된다.    
      
### 가상 메모리가 하는 일
    
가상 메모리는 실제의 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것으로 정리할 수 있다.          
이로써 작은 메모리를 가지고도 얼마든지 큰 `가상 주소 공간`을 프로그래머에게 제공할 수 있다.     
   
#### 가상 주소 공간   
   
* 한 프로세스가 메모리에 저장되는 논리적인 모습을 가상메모리에 구현한 공간이다.       
  프로세스가 요구하는 메모리 공간을 가상메모리에서 제공함으로서      
  현재 직접적으로 필요치 않은 메모리 공간은 실제 물리 메모리에 올리지 않는 것으로 물리 메모리를 절약할 수 있다.    
* 예를 들어, 한 프로그램이 실행되며 논리 메모리로 100KB 가 요구되었다고 하자.    
  하지만 실행까지에 필요한 메모리 공간`(Heap영역, Stack 영역, 코드, 데이터)`의 합이 40KB 라면, 실제 물리 메모리에는 40KB 만 올라가 있고, 나머지 60KB 만큼은 필요시에 물리메모리에 요구한다고 이해할 수 있겠다.

| `Stack` | &nbsp;&nbsp;&nbsp; free (60KB) &nbsp;&nbsp;&nbsp;&nbsp; | `Heap` | `Data` | `Code` |
| ------- | ------------------------------------------------------- | :----: | ------ | ------ |


#### 프로세스간의 페이지 공유

가상 메모리는...   
     
* `시스템 라이브러리`가 여러 프로세스들 사이에 공유될 수 있도록 한다.   
  각 프로세스들은 `공유 라이브러리`를 자신의 가상 주소 공간에 두고 사용하는 것처럼 인식하지만,      
  라이브러리가 올라가있는 `물리 메모리 페이지`들은 모든 프로세스에 공유되고 있다.  
* 프로세스들이 메모리를 공유하는 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해 통신할 수 있다.   
  이 또한, 각 프로세스들은 각자 자신의 주소 공간처럼 인식하지만, 실제 물리 메모리는 공유되고 있다.    
* `fork()`를 통한 프로세스 생성 과정에서 페이지들이 공유되는 것을 가능하게 한다.    
     
### Demand Paging(요구 페이징)
      
프로그램 실행 시작 시에 **프로그램 전체를 디스크에서 물리 메모리에 적재하는 `대신`,**      
**초기에 필요한 것들만 적재하는 전략**을 `요구 페이징`이라 하며, 가상 메모리 시스템에서 많이 사용된다.     
그리고 가상 메모리는 대개 [페이지](#paging페이징)로 관리된다.      
요구 페이징을 사용하는 가상 메모리에서는 **실행과정에서 필요해질 때 페이지들이 적재된다.**         
**한 번도 접근되지 않은 페이지는 물리 메모리에 적재되지 않는다.**     
        
프로세스 내의 개별 페이지들은 `페이저(pager)`에 의해 관리된다.          
페이저는 프로세스 실행에 `실제 필요한 페이지들만 메모리로 읽어` 옮으로서,          
**사용되지 않을 페이지를 가져오는 시간낭비와 메모리 낭비를 줄일 수 있다.**       
  
### 페이지 부재    
시간이 없어서 정리를 못할 것 같네요    
[해당 블로그를 참고 바랍니다.](https://matice.tistory.com/53)     
    
### 페이지 교체

`요구 페이징` 에서 언급된대로 **프로그램 실행시에 모든 항목이 물리 메모리에 올라오지 않기 때문에,**      
프로세스의 동작에 필요한 페이지를 요청하는 과정에서 **`page fault(페이지 부재)`가 발생하게 되면,**         
**원하는 페이지를 보조저장장치에서 가져오게 된다.**        
하지만, **만약 물리 메모리가 모두 사용중인 상황이라면, 페이지 교체가 이뤄져야 한다.**      
(또는, 운영체제가 프로세스를 강제 종료하는 방법이 있다.)   
   
#### 기본적인 방법
  
물리 메모리가 모두 사용중인 상황에서의 메모리 교체 흐름이다.   
   
1.  디스크에서 필요한 페이지의 위치를 찾는다
1.  빈 페이지 프레임을 찾는다.
    1.  `페이지 교체 알고리즘`을 통해 희생될(victim) 페이지를 고른다.
    1.  희생될 페이지를 디스크에 기록하고, 관련 페이지 테이블을 수정한다.
1.  새롭게 비워진 페이지 테이블 내 프레임에 새 페이지를 읽어오고, 프레임 테이블을 수정한다.
1.  사용자 프로세스 재시작

#### 페이지 교체 알고리즘

##### FIFO 페이지 교체
      
가장 간단한 페이지 교체 알고리즘으로 `FIFO(first-in first-out)`의 흐름을 가진다.            
즉, **물리 메모리에 먼저 들어온 페이지 순서대로 페이지 교체 시점에 먼저 나가게 된다는 것이다.**         
    
* 장점
  * 이해하기도 쉽고, 프로그램하기도 쉽다.
   
* 단점
  * 오래된 페이지가 항상 불필요하지 않은 정보를 포함하지 않을 수 있다(초기 변수 등)
  * 처음부터 활발하게 사용되는 페이지를 교체해서 페이지 부재율을 높이는 부작용을 초래할 수 있다.
  * `Belady의 모순`: 페이지를 저장할 수 있는 페이지 프레임의 갯수를 늘려도 되려 페이지 부재가 더 많이 발생하는 모순이 존재한다.

##### 최적 페이지 교체(Optimal Page Replacement)
          
`Belady의 모순`을 확인한 이후 최적 교체 알고리즘에 대한 탐구가 진행되었고,       
모든 알고리즘보다 낮은 페이지 부재율을 보이며 `Belady의 모순`이 발생하지 않는다.        
이 알고리즘의 핵심은 **`앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체`하는 것이다**   .
주로 비교 연구 목적을 위해 사용한다.
        
* 장점     
  * 알고리즘 중 가장 낮은 페이지 부재율을 보장한다.   
   
* 단점    
  * 구현의 어려움이 있다. `모든 프로세스의 메모리 참조의 계획을 미리 파악할 방법이 없기 때문`이다.    

##### LRU 페이지 교체(LRU Page Replacement)
   
`LRU: Least-Recently-Used`     
최적 알고리즘의 근사 알고리즘으로, **가장 오랫동안 사용되지 않은 페이지를 선택하여 교체한다.**   

* 특징
  * 대체적으로 `FIFO 알고리즘`보다 우수하고, `OPT알고리즘`보다는 그렇지 못한 모습을 보인다.
    
##### LFU 페이지 교체(LFU Page Replacement)
  
`LFU: Least Frequently Used`     
**참조 횟수가 가장 적은 페이지를 교체하는 방법이다.**      
활발하게 사용되는 페이지는 참조 횟수가 많아질 거라는 가정에서 만들어진 알고리즘이다.     
   
* 특징
  * 어떤 프로세스가 특정 페이지를 집중적으로 사용하다, 다른 기능을 사용하게되면   
    더 이상 사용하지 않아도 계속 메모리에 머물게 되어 초기 가정에 어긋나는 시점이 발생할 수 있다
  * 최적(OPT) 페이지 교체를 제대로 근사하지 못하기 때문에, 잘 쓰이지 않는다.

##### MFU 페이지 교체(MFU Page Replacement)
   
`MFU: Most Frequently Used`     
**참조 회수가 가장 작은 페이지가 최근에 메모리에 올라왔고, 앞으로 계속 사용될 것이라는 가정에 기반한다.**   
    
* 특징
  * 최적(OPT) 페이지 교체를 제대로 근사하지 못하기 때문에, 잘 쓰이지 않는다.
   
## 캐시의 지역성
### 캐시의 지역성 원리
      
**캐시 메모리는** 속도가 빠른 장치와 느린 장치간의 `속도차에 따른 병목 현상을 줄이기 위한 범용 메모리`이다.          
이러한 역할을 수행하기 위해서는 **CPU 가 어떤 데이터를 원할 것인가를 어느 정도 예측할 수 있어야 한다.**     
캐시의 성능은 `작은 용량의 캐시 메모리에 CPU 가 이후에 참조할, 쓸모 있는 정보가 어느 정도 들어있느냐`에 따라 좌우되기 때문이다.   
               
이 때 `적중율(Hit rate)`을 극대화 시키기 위해 데이터 **`지역성(Locality)(국부성이라고도 한다.)의 원리`** 를 사용한다.        
지역성의 전제조건으로 **프로그램은 모든 코드나 데이터를 균등하게 `Access` 하지 않는다는 특성을 기본**으로 한다.        
즉, `Locality`란 기억 장치 내의 정보를 균일하게 Access 하는 것이 아닌 **어느 한 순간에 특정 부분을 집중적으로 참조하는 특성인 것이다.**     
    
이 데이터 지역성은 대표적으로 `시간 지역성(Temporal Locality)`과 `공간 지역성(Spatial Locality)`으로 나뉜다.
      
* **시간 지역성 :** 최근에 참조된 주소의 내용은 곧 다음에 다시 참조되는 특성.  
* **공간 지역성 :** 대부분의 실제 프로그램이 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성    
   
</br>

### Caching line

언급했듯이 캐시(cache)는 프로세서 가까이에 위치하면서 빈번하게 사용되는 데이터를 놔두는 장소이다.    
하지만 캐시가 아무리 가까이 있더라도 찾고자 하는 데이터가 어느 곳에 저장되어 있는지 몰라 모든 데이터를 순회해야 한다면 시간이 오래 걸리게 된다.    
즉, 캐시에 목적 데이터가 저장되어 있다면 바로 접근하여 출력할 수 있어야 캐시가 의미 있어진다는 것이다.
   
그렇기 때문에 캐시에 데이터를 저장할 때 특정 자료구조를 사용하여 `묶음`으로 저장하게 되는데 이를 **캐싱 라인** 이라고 한다.       
다양한 주소에 있는 데이터를 사용하므로 빈번하게 사용하는 데이터의 주소는 흩어져 있다.       
따라서 캐시에 저장하는 데이터에는 데이터의 메모리 주소 등을 기록해 둔 태그를 달아놓을 필요가 있다.      
이러한 태그들의 묶음을 캐싱 라인이라고 하고 메모리로부터 가져올 때도 캐싱 라인을 기준으로 가져온다.    
종류로는 대표적으로 세 가지 방식이 존재한다.   
    
1.  Full Associative
2.  Set Associative
3.  Direct Map

